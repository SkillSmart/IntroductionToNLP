{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Textual Data in Python\n",
    "\n",
    "This Workbook records methods to efficiently load, store and restore textual data in Python\n",
    "\n",
    "Content of this workbook:\n",
    "\n",
    "* Writing Text to Files\n",
    "* Reading Text from a single file\n",
    "* Reaging Text from multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing multiple files to folder\n",
    "\n",
    "To write a larger set of text to multiple files automatically we can use loops and the file.write(Text) command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing multiple files to a folder\n",
    "text = 'This is a test text'\n",
    "for i in range(10):\n",
    "    f = open('./data/file_0{}.txt'.format(i), 'w')\n",
    "    f.write(text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading Data from a folder\n",
    "with open('./data/test.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading multiple files from a given folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_00.txt\n",
      "file_01.txt\n",
      "file_02.txt\n",
      "file_03.txt\n",
      "file_04.txt\n",
      "file_05.txt\n",
      "file_06.txt\n",
      "file_07.txt\n",
      "file_08.txt\n",
      "file_09.txt\n",
      "test_1.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for filename in os.listdir('./data'):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading multiple files and storing their results into a list\n",
    "text = []\n",
    "for filename in os.listdir('./data'):\n",
    "    with open('./data/{}'.format(filename), 'r') as f:\n",
    "        text.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a testfile\\n']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Generator\n",
    "\n",
    "With large Datasets it might be better to read them file by file using a generator that iterates over all the files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading multiple files and concatenating the results\n",
    "def text_reader(folder):\n",
    "    for f in os.listdir(folder):\n",
    "        with open('{}/{}'.format(folder, f), 'r') as file:\n",
    "            yield file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the Generator we can not read it document by document at any point in time we need it\n",
    "a = text_reader('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test text'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.__next__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing python objects to disk\n",
    "\n",
    "Once we are done with creating a specific preprocessed text object we want to get back to later, we can pickle it and save it to disc (We serialize the object).\n",
    "\n",
    "Pickle serializes the object as a binary stream of data, and as such the file we open has to be opened in binary writing mode aka 'wb'. Otherwise we get a confusing error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/text_corpus.pkl', 'wb') as f:\n",
    "    pickle.dump(text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file_00.txt',\n",
       " 'file_01.txt',\n",
       " 'file_02.txt',\n",
       " 'file_03.txt',\n",
       " 'file_04.txt',\n",
       " 'file_05.txt',\n",
       " 'file_06.txt',\n",
       " 'file_07.txt',\n",
       " 'file_08.txt',\n",
       " 'file_09.txt',\n",
       " 'test_1.txt',\n",
       " 'text_corpus.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check for the existence of our pickle file\n",
    "os.listdir('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To return this move we can retrieve the object from the pckl dump\n",
    "b = pickle.load(open('./data/text_corpus.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a test text',\n",
       " 'This is a testfile\\n']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
