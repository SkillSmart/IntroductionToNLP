{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing and Correcting Words\n",
    "\n",
    "In this chapter, we will go over various word replacement and correction techniques. <br>\n",
    "The recipes cover the gamut of: \n",
    "- linguistic compression, \n",
    "- spelling correction, and \n",
    "- text normalization. \n",
    "\n",
    "<br>All of these methods can be **very useful for preprocessing text before search indexing, document classification, and text analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming words - Text Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_examples(Stemmer, lemmatize=False):\n",
    "    text = \"\"\"\n",
    "    The PorterStemmer class knows a number of regular word forms and suffixes and uses  this knowledge \n",
    "    to transform your input word to a final stem through a series of steps. The resulting stem is often a \n",
    "    shorter word, or at least a common form of the word, which has  the same root meaning\n",
    "    \"\"\"\n",
    "    if lemmatize:\n",
    "        return ' '.join([Stemmer.lemmatize(word) for word in nltk.word_tokenize(text)])\n",
    "    return ' '.join([Stemmer.stem(word) for word in nltk.word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using the regex based Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the porterstemm class know a number of regular word form and suffix and use thi knowledg to transform your input word to a final stem through a seri of step . the result stem is often a shorter word , or at least a common form of the word , which ha the same root mean'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_examples(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PorterStemmer class knows a number of regular word forms and suffixes and uses  this knowledge to transform your input word to a final stem through a series of steps. The resulting stem is often a shorter word, or at least a common form of the word, which has  the same root meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the porterstem class know a numb of regul word form and suffix and us thi knowledg to transform yo input word to a fin stem through a sery of step . the result stem is oft a short word , or at least a common form of the word , which has the sam root mean'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_examples(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snowball Stemmer\n",
    "\n",
    "The SnowballStemmer class supports 13 non-English languages. It also provides two English stemmers: the original porter algorithm as well as the new English stemming algorithm. To use the SnowballStemmer class, create an instance with the name of the language you are using and then call the stem() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'danish; dutch; english; finnish; french; german; hungarian; italian; norwegian; porter; portuguese; romanian; russian; spanish; swedish'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "'; '.join(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the porterstem class know a numb of regul word form and suffix and us thi knowledg to transform yo input word to a fin stem through a sery of step . the result stem is oft a short word , or at least a common form of the word , which has the sam root mean'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_examples(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regex Stemmer\n",
    "\n",
    " It takes  a single regular expression (either compiled or as a string) and removes any prefix or  suffix that matches the expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmer = RegexpStemmer('ing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The PorterStemmer class knows a number of regular word forms and suffixes and uses this knowledge to transform your input word to a final stem through a series of steps . The result stem is often a shorter word , or at least a common form of the word , which has the same root mean'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_examples(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing Words\n",
    "Lemmatization is very similar to stemming, but is more akin to synonym replacement.  A lemma is a root word, as opposed to the root stem. So unlike stemming, you are always  left with a valid word that means the same thing. However, the word you end up with can  be completely differen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The PorterStemmer class know a number of regular word form and suffix and us this knowledge to transform your input word to a final stem through a series of step . The resulting stem is often a shorter word , or at least a common form of the word , which ha the same root meaning'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_examples(lemmatizer, lemmatize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WordNetLemmatizer class is a thin wrapper around the wordnet corpus and uses the **morphy()** function of the WordNetCorpusReader class to find a lemma. If no lemma is found, or the word itself is a lemma, the word is returned as is. Unlike with stemming, knowing the part of speech of the word is important. As demonstrated previously, cooking does not return a different lemma unless you specify that the POS is a verb. This is because the default POS is a noun, and as a noun, cooking is its own lemma. On the other hand, cookbooks  is a noun with its singular form, cookbook, as its lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Text Compression\n",
    "\n",
    "In cases where it is important to reach a maximum of Text compression, we can combine the effects of Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# apply both processes\n",
    "def max_compression(sentence):\n",
    "    return [lemmatizer.lemmatize(stemmer.stem(word)) for word in nltk.word_tokenize(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original text has a lenght of 306, and after compression retains a length of 269\n",
      "This is a reduction of 0.12 %\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "    The PorterStemmer class knows a number of regular word forms and suffixes and uses  this knowledge \n",
    "    to transform your input word to a final stem through a series of steps. The resulting stem is often a \n",
    "    shorter word, or at least a common form of the word, which has  the same root meaning\n",
    "    \"\"\"\n",
    "print('The original text has a lenght of {}, and after compression retains a length of {}'\n",
    "      .format(len(text), len(' '.join(max_compression(text)))))\n",
    "print('This is a reduction of {:0.2f} %'.format(1 - len(' '.join(max_compression(text)))/ len(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing words with regEx\n",
    "\n",
    "To clean up slang and missspellings, we can use manual rue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "replacement_patterns = [\n",
    "    (r'ain\\'t', 'are not'),\n",
    "    (r'gonna', 'going to'),\n",
    "    (r'won\\'t', 'will not'),\n",
    "    (r'can\\'t', 'can not'),\n",
    "    (r'i\\'m', 'i am'),\n",
    "    (r'ain\\'t', 'is not'),\n",
    "    (r'(\\w+)\\'ll', '\\g<1> will')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RegexReplacer(object):\n",
    "    def __init__(self, patterns=replacement_patterns):\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "        \n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            text = re.sub(pattern, repl, text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are not going to believe that i can not express how greatfull i am that i am back'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer = RegexReplacer()\n",
    "replacer.replace(\"You ain't gonna believe that i can't express how greatfull i am that i'm back\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing redunandt characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class RepeatReplacer(object):\n",
    "    def __init__(self):\n",
    "        self.repeate_regexp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
