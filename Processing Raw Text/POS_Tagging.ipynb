{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve some generic web text\n",
    "def get_page(url, clean=True):\n",
    "    response = request.urlopen(url)\n",
    "    raw = response.read()\n",
    "    if clean:\n",
    "        return BeautifulSoup(raw, \"lxml\").getText()\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = get_page('http://mostly.ai/summit/#undefined', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Tokenize the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse Text into words inside sentences\n",
    "word_sentences = [nltk.word_tokenize(sentence) for sentence in nltk.sent_tokenize(text)]\n",
    "\n",
    "# Stem the words\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Identify the POS for the words\n",
    "tagged = nltk.pos_tag(nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AI', 'NNP'),\n",
       " ('Summit', 'NNP'),\n",
       " ('Vienna', 'NNP'),\n",
       " ('AI', 'NNP'),\n",
       " ('Advances', 'NNP'),\n",
       " ('Insights', 'NNP'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('latest', 'JJS'),\n",
       " ('advances', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('field', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('where', 'WRB'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('heading', 'VBG'),\n",
       " ('.', '.'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('Dive', 'NNP'),\n",
       " ('into', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('powerful', 'JJ'),\n",
       " ('model', 'NN'),\n",
       " ('classes', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('are', 'VBP'),\n",
       " ('behind', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('current', 'JJ'),\n",
       " ('AI', 'NNP'),\n",
       " ('revival', 'NN'),\n",
       " ('.', '.'),\n",
       " ('ML', 'NNP'),\n",
       " ('Use', 'NNP'),\n",
       " ('Cases', 'VBZ'),\n",
       " ('Real-world', 'NNP'),\n",
       " ('applications', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('shared', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('seasoned', 'JJ'),\n",
       " ('practitioners', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Networking', 'VBG'),\n",
       " ('Informal', 'JJ'),\n",
       " ('get-to-gether', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('AI', 'NNP'),\n",
       " ('enthusiasts', 'NNS'),\n",
       " ('at', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('Europe', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('most', 'JJS'),\n",
       " ('modern', 'JJ'),\n",
       " ('campuses', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Learn', 'VB'),\n",
       " ('from', 'IN'),\n",
       " ('Leading', 'VBG'),\n",
       " ('AI', 'NNP'),\n",
       " ('Experts', 'NNP'),\n",
       " ('Self-learning', 'NNP'),\n",
       " ('machines', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('outperforming', 'VBG'),\n",
       " ('humans', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('decision', 'NN'),\n",
       " ('making', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('ever', 'RB'),\n",
       " ('increasing', 'VBG'),\n",
       " ('pace', 'NN'),\n",
       " ('.', '.'),\n",
       " ('These', 'DT'),\n",
       " ('on-going', 'JJ'),\n",
       " ('advancements', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('fueled', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('1', 'CD'),\n",
       " (')', ')'),\n",
       " ('more', 'RBR'),\n",
       " ('efficient', 'JJ'),\n",
       " ('algorithms', 'NN'),\n",
       " (',', ','),\n",
       " ('2', 'CD'),\n",
       " (')', ')'),\n",
       " ('faster', 'RBR'),\n",
       " ('processing', 'VBG'),\n",
       " ('power', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('3', 'CD'),\n",
       " (')', ')'),\n",
       " ('an', 'DT'),\n",
       " ('expontential', 'JJ'),\n",
       " ('growth', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('data', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('By', 'IN'),\n",
       " ('bringing', 'VBG'),\n",
       " ('together', 'RB'),\n",
       " ('leading', 'VBG'),\n",
       " ('AI', 'NNP'),\n",
       " ('researchers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('practitioners', 'NNS'),\n",
       " ('here', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('Vienna', 'NNP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('unique', 'JJ'),\n",
       " ('opportunity', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('go', 'VB'),\n",
       " ('beyond', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('hype', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('gain', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('practical', 'JJ'),\n",
       " ('understanding', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('artificial', 'JJ'),\n",
       " ('intelligence', 'NN'),\n",
       " (',', ','),\n",
       " ('its', 'PRP$'),\n",
       " ('potential', 'JJ'),\n",
       " (',', ','),\n",
       " ('as', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('underlying', 'JJ'),\n",
       " ('algorithms', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Our', 'PRP$'),\n",
       " ('Promise', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('non-profit', 'JJ'),\n",
       " (',', ','),\n",
       " ('content-rich', 'JJ'),\n",
       " ('AI', 'NNP'),\n",
       " ('Summit', 'NNP'),\n",
       " ('tailored', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('a', 'DT'),\n",
       " ('forward-thinking', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('tech-savvy', 'JJ'),\n",
       " ('audience', 'NN'),\n",
       " ('Program', 'NNP'),\n",
       " ('Slides', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('made', 'VBN'),\n",
       " ('available', 'JJ'),\n",
       " ('as', 'RB'),\n",
       " ('soon', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('possible', 'JJ'),\n",
       " ('(', '('),\n",
       " ('hopefully', 'RB'),\n",
       " ('by', 'IN'),\n",
       " ('end', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Thu', 'NNP'),\n",
       " ('7.9.', 'CD'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('Videos', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('talks', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('go', 'VB'),\n",
       " ('online', 'NN'),\n",
       " ('within', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('second', 'JJ'),\n",
       " ('half', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('September', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('September', 'NNP'),\n",
       " ('04', 'CD'),\n",
       " ('AI', 'NNP'),\n",
       " ('Summit', 'NNP'),\n",
       " ('Vienna', 'NNP'),\n",
       " ('1530', 'CD'),\n",
       " ('1600', 'CD'),\n",
       " ('Check-in', 'JJ'),\n",
       " ('Collect', 'NNP'),\n",
       " ('your', 'PRP$'),\n",
       " ('entrance', 'NN'),\n",
       " ('pass', 'NN'),\n",
       " ('.', '.'),\n",
       " ('1600', 'CD'),\n",
       " ('1620', 'CD'),\n",
       " ('Welcome', 'NNP'),\n",
       " ('You', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('made', 'VBN'),\n",
       " ('it', 'PRP'),\n",
       " ('!', '.'),\n",
       " ('1620', 'CD'),\n",
       " ('1700', 'CD'),\n",
       " ('Machine', 'NNP'),\n",
       " ('Learning', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('Google', 'NNP'),\n",
       " ('Cloud', 'NNP'),\n",
       " ('Dave', 'NNP'),\n",
       " ('Elliott', 'NNP'),\n",
       " ('Google', 'NNP'),\n",
       " (',', ','),\n",
       " ('Global', 'NNP'),\n",
       " ('Product', 'NNP'),\n",
       " ('Lead', 'NNP'),\n",
       " ('1700', 'CD'),\n",
       " ('1740', 'CD'),\n",
       " ('Neural', 'NNP'),\n",
       " ('Networks', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('Natural', 'NNP'),\n",
       " ('Language', 'NNP'),\n",
       " ('Processing', 'NNP'),\n",
       " ('Tomáš', 'NNP'),\n",
       " ('Mikolov', 'NNP'),\n",
       " ('Facebook', 'NNP'),\n",
       " (',', ','),\n",
       " ('AI', 'NNP'),\n",
       " ('Research', 'NNP'),\n",
       " ('Scientist', 'NNP'),\n",
       " ('1740', 'CD'),\n",
       " ('1820', 'CD'),\n",
       " ('Break', 'NNP'),\n",
       " ('Snacks', 'NNP'),\n",
       " ('&', 'CC'),\n",
       " ('drinks', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('1820', 'CD'),\n",
       " ('1900', 'CD'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('Evolving', 'VBG'),\n",
       " ('into', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Key', 'NNP'),\n",
       " ('Technology', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Artificial', 'NNP'),\n",
       " ('Intelligence', 'NNP'),\n",
       " ('Sepp', 'NNP'),\n",
       " ('Hochreiter', 'NNP'),\n",
       " ('JKU', 'NNP'),\n",
       " ('Linz', 'NNP'),\n",
       " (',', ','),\n",
       " ('Head', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Institute', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Bioinformatics', 'NNP'),\n",
       " ('1900', 'CD'),\n",
       " ('1940', 'CD'),\n",
       " ('Seizing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('Machine', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('Opportunity', 'NNP'),\n",
       " ('Ulla', 'NNP'),\n",
       " ('Kruhse-Lehtonen', 'NNP'),\n",
       " ('DAIN', 'NNP'),\n",
       " ('Studios', 'NNP'),\n",
       " (',', ','),\n",
       " ('CEO', 'NNP'),\n",
       " ('1940', 'CD'),\n",
       " ('2020', 'CD'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " (':', ':'),\n",
       " ('More', 'JJR'),\n",
       " ('Than', 'NNP'),\n",
       " ('Classification', 'NNP'),\n",
       " ('Calvin', 'NNP'),\n",
       " ('Seward', 'NNP'),\n",
       " ('Zalando', 'NNP'),\n",
       " (',', ','),\n",
       " ('Research', 'NNP'),\n",
       " ('Scientist', 'NNP'),\n",
       " ('2020', 'CD'),\n",
       " ('2359', 'CD'),\n",
       " ('After-Event', 'JJ'),\n",
       " ('Networking', 'NNP'),\n",
       " ('Snacks', 'NNP'),\n",
       " ('&', 'CC'),\n",
       " ('drinks.Sponsored', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('s', 'NN'),\n",
       " ('IT', 'NNP'),\n",
       " ('Solutions', 'NNP'),\n",
       " ('Austria', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('Venue', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('AI', 'NNP'),\n",
       " ('Summit', 'NNP'),\n",
       " ('Vienna', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('take', 'VB'),\n",
       " ('place', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('festival', 'NN'),\n",
       " ('hall', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('WU', 'NNP'),\n",
       " ('Wien', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('Learning', 'NNP'),\n",
       " ('Center', 'NNP'),\n",
       " ('(', '('),\n",
       " ('depicted', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('image', 'NN'),\n",
       " ('below', 'NN'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('Check', 'VB'),\n",
       " ('Google', 'NNP'),\n",
       " ('Maps', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('directions', 'NNS'),\n",
       " ('how', 'WRB'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('there', 'RB'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('recommended', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('arrive', 'VB'),\n",
       " ('by', 'IN'),\n",
       " ('public', 'JJ'),\n",
       " ('transport', 'NN'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('nearest', 'JJS'),\n",
       " ('subway', 'NN'),\n",
       " ('stations', 'NNS'),\n",
       " ('being', 'VBG'),\n",
       " ('U2', 'NNP'),\n",
       " ('Krieau', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('U2', 'NNP'),\n",
       " ('Messe-Prater', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Learning', 'NNP'),\n",
       " ('Center', 'NNP'),\n",
       " ('WU', 'NNP'),\n",
       " ('Wiendesigned', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('star', 'NN'),\n",
       " ('architect', 'NN'),\n",
       " ('Zaha', 'NNP'),\n",
       " ('Hadid', 'NNP'),\n",
       " ('Tickets', 'NNP'),\n",
       " ('Attendance', 'NNP'),\n",
       " ('8', 'CD'),\n",
       " ('EUR', 'NNP'),\n",
       " ('Sold', 'VBN'),\n",
       " ('Out', 'RP'),\n",
       " ('Startup', 'NNP'),\n",
       " ('Table', 'NNP'),\n",
       " ('250', 'CD'),\n",
       " ('EUR', 'NNP'),\n",
       " ('Sold', 'VBN'),\n",
       " ('Out', 'NNP'),\n",
       " ('Tickets', 'NNP'),\n",
       " ('grant', 'JJ'),\n",
       " ('access', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('all', 'DT'),\n",
       " ('sessions', 'NNS'),\n",
       " (',', ','),\n",
       " ('coffee', 'NN'),\n",
       " ('breaks', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('after-summit', 'JJ'),\n",
       " ('get-to-gether', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Note', 'NN'),\n",
       " (':', ':'),\n",
       " ('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('independent', 'JJ'),\n",
       " (',', ','),\n",
       " ('volunteer-organized', 'JJ'),\n",
       " (',', ','),\n",
       " ('not-for-profit', 'JJ'),\n",
       " ('event', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('set', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('price', 'NN'),\n",
       " ('as', 'RB'),\n",
       " ('low', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('possible', 'JJ'),\n",
       " (',', ','),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('accessible', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('everyone', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Ticket', 'NNP'),\n",
       " ('revenues', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('solely', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('used', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('cover', 'VB'),\n",
       " ('location', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('catering', 'NN'),\n",
       " ('costs', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('All', 'DT'),\n",
       " ('our', 'PRP$'),\n",
       " ('speakers', 'NNS'),\n",
       " ('agreed', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('come', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('free', 'JJ'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('very', 'RB'),\n",
       " ('grateful', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('support', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('community', 'NN'),\n",
       " ('!', '.'),\n",
       " ('After-Event', 'JJ'),\n",
       " ('Sponsor', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('Organizers', 'NNP'),\n",
       " ('Michael', 'NNP'),\n",
       " ('Platzer', 'NNP'),\n",
       " ('Thomas', 'NNP'),\n",
       " ('Lidy', 'NNP'),\n",
       " ('Jan', 'NNP'),\n",
       " ('Schlüter', 'NNP'),\n",
       " ('Alex', 'NNP'),\n",
       " ('Schindler', 'NNP'),\n",
       " ('Thomas', 'NNP'),\n",
       " ('Reutterer', 'NNP'),\n",
       " ('Belinda', 'NNP'),\n",
       " ('Haid', 'NNP'),\n",
       " ('Links', 'NNP'),\n",
       " ('Mostly', 'NNP'),\n",
       " ('AI', 'NNP'),\n",
       " ('Vienna', 'NNP'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('Meetup', 'NNP'),\n",
       " ('Institut', 'NNP'),\n",
       " ('für', 'NN'),\n",
       " ('Service', 'NNP'),\n",
       " ('Marketing', 'NNP'),\n",
       " ('Contacts', 'NNP'),\n",
       " ('summit', 'NN'),\n",
       " ('@', 'NNP'),\n",
       " ('mostly.ai', 'NN'),\n",
       " ('Further', 'NNP'),\n",
       " ('Code', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Conduct', 'NNP'),\n",
       " ('©', 'NNP'),\n",
       " ('2017', 'CD'),\n",
       " ('Based', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('Project', 'NNP'),\n",
       " ('Zeppelin', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Designed', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('created', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('Oleh', 'NNP'),\n",
       " ('Zasadnyy', 'NNP'),\n",
       " ('·', 'NNP'),\n",
       " ('GDG', 'NNP'),\n",
       " ('Lviv', 'NNP'),\n",
       " ('Check-in', 'NNP'),\n",
       " ('Collect', 'NNP'),\n",
       " ('your', 'PRP$'),\n",
       " ('entrance', 'NN'),\n",
       " ('pass', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Welcome', 'NNP'),\n",
       " ('You', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('made', 'VBN'),\n",
       " ('it', 'PRP'),\n",
       " ('!', '.'),\n",
       " ('Break', 'NNP'),\n",
       " ('Snacks', 'NNP'),\n",
       " ('&', 'CC'),\n",
       " ('drinks', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('After-Event', 'JJ'),\n",
       " ('Networking', 'NNP'),\n",
       " ('Snacks', 'NNP'),\n",
       " ('&', 'CC'),\n",
       " ('drinks.Sponsored', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('s', 'NN'),\n",
       " ('IT', 'NNP'),\n",
       " ('Solutions', 'NNP'),\n",
       " ('Austria', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('Evolving', 'VBG'),\n",
       " ('into', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Key', 'NNP'),\n",
       " ('Technology', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Artificial', 'NNP'),\n",
       " ('Intelligence', 'NNP'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('emerged', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('successful', 'JJ'),\n",
       " ('fields', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('artificial', 'JJ'),\n",
       " ('intelligence', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('overwhelming', 'JJ'),\n",
       " ('success', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('industrial', 'JJ'),\n",
       " ('speech', 'NN'),\n",
       " (',', ','),\n",
       " ('language', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('vision', 'NN'),\n",
       " ('benchmarks', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Consequently', 'RB'),\n",
       " ('it', 'PRP'),\n",
       " ('became', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('central', 'JJ'),\n",
       " ('field', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('research', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('IT', 'NNP'),\n",
       " ('giants', 'VBZ'),\n",
       " ('like', 'IN'),\n",
       " ('Google', 'NNP'),\n",
       " (',', ','),\n",
       " ('facebook', 'NN'),\n",
       " (',', ','),\n",
       " ('Microsoft', 'NNP'),\n",
       " (',', ','),\n",
       " ('Baidu', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('Amazon', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('founded', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('novel', 'JJ'),\n",
       " ('neural', 'JJ'),\n",
       " ('network', 'NN'),\n",
       " ('techniques', 'NNS'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('recent', 'JJ'),\n",
       " ('availability', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('very', 'RB'),\n",
       " ('fast', 'JJ'),\n",
       " ('computers', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('massive', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('sets', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('core', 'NN'),\n",
       " (',', ','),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('discovers', 'VBZ'),\n",
       " ('multiple', 'JJ'),\n",
       " ('levels', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('abstract', 'JJ'),\n",
       " ('representations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('input', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('obstacle', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('learning', 'VBG'),\n",
       " ('deep', 'JJ'),\n",
       " ('neural', 'JJ'),\n",
       " ('networks', 'NNS'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('vanishing', 'VBG'),\n",
       " ('gradient', 'NN'),\n",
       " ('problem', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('vanishing', 'VBG'),\n",
       " ('gradient', 'NN'),\n",
       " ('impedes', 'NNS'),\n",
       " ('credit', 'NN'),\n",
       " ('assignment', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('layers', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('deep', 'JJ'),\n",
       " ('network', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('early', 'JJ'),\n",
       " ('elements', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('sequence', 'NN'),\n",
       " (',', ','),\n",
       " ('therefore', 'RB'),\n",
       " ('limits', 'NNS'),\n",
       " ('model', 'NN'),\n",
       " ('selection', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('show', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('success', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('concepts', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('unsupervised', 'JJ'),\n",
       " ('stacking', 'NN'),\n",
       " (',', ','),\n",
       " ('ReLUs', 'NNP'),\n",
       " (',', ','),\n",
       " ('residual', 'JJ'),\n",
       " ('networks', 'NNS'),\n",
       " (',', ','),\n",
       " ('highway', 'NN'),\n",
       " ('networks', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('LSTM', 'NNP'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('traced', 'VBN'),\n",
       " ('back', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('avoiding', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('vanishing', 'NN'),\n",
       " ('gradient', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('present', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('current', 'JJ'),\n",
       " ('research', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('self-normalizing', 'JJ'),\n",
       " ('neural', 'JJ'),\n",
       " ('networks', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('suffer', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('exploding', 'VBG'),\n",
       " ('or', 'CC'),\n",
       " ('vanishing', 'VBG'),\n",
       " ('gradients', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('converge', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('optimal', 'VB'),\n",
       " ('learning', 'VBG'),\n",
       " ('states', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Currently', 'RB'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('advance', 'VBP'),\n",
       " ('generative', 'JJ'),\n",
       " ('adversarial', 'JJ'),\n",
       " ('networks', 'NNS'),\n",
       " ('(', '('),\n",
       " ('GANs', 'NNP'),\n",
       " (')', ')'),\n",
       " ('by', 'IN'),\n",
       " ('stochastic', 'JJ'),\n",
       " ('approximation', 'NN'),\n",
       " ('theory', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('allows', 'VBZ'),\n",
       " ('proofing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('convergence', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('GAN', 'NNP'),\n",
       " ('learning', 'VBG'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('AUDI', 'NNP'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('Center', 'NNP'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('heading', 'VBG'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('apply', 'VBP'),\n",
       " ('Deep', 'JJ'),\n",
       " ('Learning', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('advance', 'VB'),\n",
       " ('autonomous', 'JJ'),\n",
       " ('driving', 'VBG'),\n",
       " ('using', 'VBG'),\n",
       " ('LSTMs', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('sequence', 'NN'),\n",
       " ('prediction', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('for', 'IN'),\n",
       " ('attention', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('use', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('or', 'CC'),\n",
       " ('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('(', '('),\n",
       " ('NLP', 'NNP'),\n",
       " (')', ')'),\n",
       " ('in', 'IN'),\n",
       " ('collaboration', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('companies', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('Zalando', 'NNP'),\n",
       " (',', ','),\n",
       " ('e.g', 'NN'),\n",
       " ('.', '.'),\n",
       " ('to', 'TO'),\n",
       " ('analyze', 'VB'),\n",
       " ('fashion', 'NN'),\n",
       " ('blogs', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Using', 'VBG'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('won', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('NIH', 'NNP'),\n",
       " ('Tox21', 'NNP'),\n",
       " ('challenge', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('identified', 'VBD'),\n",
       " ('unknown', 'JJ'),\n",
       " ('side', 'NN'),\n",
       " ('effects', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('drug', 'NN'),\n",
       " ('candidates', 'NNS'),\n",
       " ('based', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('data', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('bioassays', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('high', 'JJ'),\n",
       " ('content', 'NN'),\n",
       " ('imaging', 'VBG'),\n",
       " ('.', '.'),\n",
       " ('View', 'NNP'),\n",
       " ('presentation', 'NN'),\n",
       " ('Sepp', 'NNP'),\n",
       " ('Hochreiter', 'NNP'),\n",
       " ('Head', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Institute', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Bioinformatics', 'NNP'),\n",
       " (',', ','),\n",
       " ('JKU', 'NNP'),\n",
       " ('Linz', 'NNP'),\n",
       " ('Sepp', 'NNP'),\n",
       " ('Hochreiter', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('heading', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('Institute', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Bioinformatics', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Johannes', 'NNP'),\n",
       " ('Kepler', 'NNP'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Linz', 'NNP'),\n",
       " (',', ','),\n",
       " ('Austria', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('works', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('fields', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('bioinformatics', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('pioneer', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('best', 'JJS'),\n",
       " ('known', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('developing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('long', 'JJ'),\n",
       " ('short', 'JJ'),\n",
       " ('term', 'NN'),\n",
       " ('memory', 'NN'),\n",
       " ('(', '('),\n",
       " ('LSTM', 'NNP'),\n",
       " (')', ')'),\n",
       " ('in', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('diploma', 'NN'),\n",
       " ('thesis', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('1991', 'CD'),\n",
       " ('which', 'WDT'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('published', 'VBN'),\n",
       " ('later', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('1997', 'CD'),\n",
       " ('.', '.'),\n",
       " ('Since', 'IN'),\n",
       " ('2012', 'CD'),\n",
       " (',', ','),\n",
       " ('LSTM', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('used', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('Google', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'NN'),\n",
       " ('Android', 'NNP'),\n",
       " ('speech', 'NN'),\n",
       " ('recognizer', 'NN'),\n",
       " (',', ','),\n",
       " ('since', 'IN'),\n",
       " ('2015', 'CD'),\n",
       " ('in', 'IN'),\n",
       " ('Google', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'JJ'),\n",
       " ('Voice', 'NNP'),\n",
       " ('transcription', 'NN'),\n",
       " (',', ','),\n",
       " ('since', 'IN'),\n",
       " ('2016', 'CD'),\n",
       " ('in', 'IN'),\n",
       " ('Google', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'NN'),\n",
       " ('Allo', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('since', 'IN'),\n",
       " ('2016', 'CD'),\n",
       " ('in', 'IN'),\n",
       " ('Apple', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('iOS', 'JJ'),\n",
       " ('10', 'CD'),\n",
       " ('QuickType', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Currently', 'NNP'),\n",
       " (',', ','),\n",
       " ('Sepp', 'NNP'),\n",
       " ('Hochreiter', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('advancing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('theoretical', 'JJ'),\n",
       " ('foundation', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('by', 'IN'),\n",
       " ('analyzing', 'VBG'),\n",
       " ('gradient', 'NN'),\n",
       " ('flow', 'NN'),\n",
       " ('through', 'IN'),\n",
       " ('deep', 'JJ'),\n",
       " ('networks', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('self-normalizing', 'JJ'),\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all Nouns in the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allnouns = [word for word, pos in tagged if pos in['NN', 'NNP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI',\n",
       " 'Summit',\n",
       " 'Vienna',\n",
       " 'AI',\n",
       " 'Advances',\n",
       " 'Insights',\n",
       " 'field',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'Dive',\n",
       " 'model',\n",
       " 'AI',\n",
       " 'revival',\n",
       " 'ML',\n",
       " 'Use',\n",
       " 'Real-world',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'get-to-gether',\n",
       " 'AI',\n",
       " 'Europe',\n",
       " 'AI',\n",
       " 'Experts',\n",
       " 'Self-learning',\n",
       " 'decision',\n",
       " 'making',\n",
       " 'pace',\n",
       " 'algorithms',\n",
       " 'power',\n",
       " 'growth',\n",
       " 'AI',\n",
       " 'Vienna',\n",
       " 'opportunity',\n",
       " 'hype',\n",
       " 'understanding',\n",
       " 'intelligence',\n",
       " 'algorithms',\n",
       " 'Promise',\n",
       " 'AI',\n",
       " 'Summit',\n",
       " 'audience',\n",
       " 'Program',\n",
       " 'Slides',\n",
       " 'end',\n",
       " 'Thu',\n",
       " 'Videos',\n",
       " 'online',\n",
       " 'half',\n",
       " 'September',\n",
       " 'September',\n",
       " 'AI',\n",
       " 'Summit',\n",
       " 'Vienna',\n",
       " 'Collect',\n",
       " 'entrance',\n",
       " 'pass',\n",
       " 'Welcome',\n",
       " 'Machine',\n",
       " 'Google',\n",
       " 'Cloud',\n",
       " 'Dave',\n",
       " 'Elliott',\n",
       " 'Google',\n",
       " 'Global',\n",
       " 'Product',\n",
       " 'Lead',\n",
       " 'Neural',\n",
       " 'Networks',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'Tomáš',\n",
       " 'Mikolov',\n",
       " 'Facebook',\n",
       " 'AI',\n",
       " 'Research',\n",
       " 'Scientist',\n",
       " 'Break',\n",
       " 'Snacks',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'Key',\n",
       " 'Technology',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'Sepp',\n",
       " 'Hochreiter',\n",
       " 'JKU',\n",
       " 'Linz',\n",
       " 'Head',\n",
       " 'Institute',\n",
       " 'Bioinformatics',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'Opportunity',\n",
       " 'Ulla',\n",
       " 'Kruhse-Lehtonen',\n",
       " 'DAIN',\n",
       " 'Studios',\n",
       " 'CEO',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'Than',\n",
       " 'Classification',\n",
       " 'Calvin',\n",
       " 'Seward',\n",
       " 'Zalando',\n",
       " 'Research',\n",
       " 'Scientist',\n",
       " 'Networking',\n",
       " 'Snacks',\n",
       " 's',\n",
       " 'IT',\n",
       " 'Solutions',\n",
       " 'Austria',\n",
       " 'Venue',\n",
       " 'AI',\n",
       " 'Summit',\n",
       " 'Vienna',\n",
       " 'place',\n",
       " 'festival',\n",
       " 'hall',\n",
       " 'WU',\n",
       " 'Wien',\n",
       " 'Learning',\n",
       " 'Center',\n",
       " 'image',\n",
       " 'below',\n",
       " 'Google',\n",
       " 'Maps',\n",
       " 'transport',\n",
       " 'subway',\n",
       " 'U2',\n",
       " 'Krieau',\n",
       " 'U2',\n",
       " 'Messe-Prater',\n",
       " 'Learning',\n",
       " 'Center',\n",
       " 'WU',\n",
       " 'star',\n",
       " 'architect',\n",
       " 'Zaha',\n",
       " 'Hadid',\n",
       " 'Tickets',\n",
       " 'Attendance',\n",
       " 'EUR',\n",
       " 'Startup',\n",
       " 'Table',\n",
       " 'EUR',\n",
       " 'Out',\n",
       " 'Tickets',\n",
       " 'access',\n",
       " 'coffee',\n",
       " 'get-to-gether',\n",
       " 'Note',\n",
       " 'event',\n",
       " 'price',\n",
       " 'everyone',\n",
       " 'Ticket',\n",
       " 'location',\n",
       " 'catering',\n",
       " 'support',\n",
       " 'community',\n",
       " 'Sponsor',\n",
       " 'Organizers',\n",
       " 'Michael',\n",
       " 'Platzer',\n",
       " 'Thomas',\n",
       " 'Lidy',\n",
       " 'Jan',\n",
       " 'Schlüter',\n",
       " 'Alex',\n",
       " 'Schindler',\n",
       " 'Thomas',\n",
       " 'Reutterer',\n",
       " 'Belinda',\n",
       " 'Haid',\n",
       " 'Links',\n",
       " 'Mostly',\n",
       " 'AI',\n",
       " 'Vienna',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'Meetup',\n",
       " 'Institut',\n",
       " 'für',\n",
       " 'Service',\n",
       " 'Marketing',\n",
       " 'Contacts',\n",
       " 'summit',\n",
       " '@',\n",
       " 'mostly.ai',\n",
       " 'Further',\n",
       " 'Code',\n",
       " 'Conduct',\n",
       " '©',\n",
       " 'Project',\n",
       " 'Zeppelin',\n",
       " 'Oleh',\n",
       " 'Zasadnyy',\n",
       " '·',\n",
       " 'GDG',\n",
       " 'Lviv',\n",
       " 'Check-in',\n",
       " 'Collect',\n",
       " 'entrance',\n",
       " 'pass',\n",
       " 'Welcome',\n",
       " 'Break',\n",
       " 'Snacks',\n",
       " 'Networking',\n",
       " 'Snacks',\n",
       " 's',\n",
       " 'IT',\n",
       " 'Solutions',\n",
       " 'Austria',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'Key',\n",
       " 'Technology',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'intelligence',\n",
       " 'success',\n",
       " 'speech',\n",
       " 'language',\n",
       " 'vision',\n",
       " 'field',\n",
       " 'research',\n",
       " 'IT',\n",
       " 'Google',\n",
       " 'facebook',\n",
       " 'Microsoft',\n",
       " 'Baidu',\n",
       " 'Amazon',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'network',\n",
       " 'availability',\n",
       " 'core',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'input',\n",
       " 'obstacle',\n",
       " 'gradient',\n",
       " 'problem',\n",
       " 'gradient',\n",
       " 'credit',\n",
       " 'assignment',\n",
       " 'network',\n",
       " 'sequence',\n",
       " 'model',\n",
       " 'selection',\n",
       " 'success',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'stacking',\n",
       " 'ReLUs',\n",
       " 'highway',\n",
       " 'LSTM',\n",
       " 'vanishing',\n",
       " 'gradient',\n",
       " 'research',\n",
       " 'converge',\n",
       " 'GANs',\n",
       " 'approximation',\n",
       " 'theory',\n",
       " 'convergence',\n",
       " 'GAN',\n",
       " 'AUDI',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'Center',\n",
       " 'Learning',\n",
       " 'LSTMs',\n",
       " 'sequence',\n",
       " 'prediction',\n",
       " 'attention',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'NLP',\n",
       " 'collaboration',\n",
       " 'Zalando',\n",
       " 'e.g',\n",
       " 'fashion',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'NIH',\n",
       " 'Tox21',\n",
       " 'challenge',\n",
       " 'side',\n",
       " 'drug',\n",
       " 'content',\n",
       " 'View',\n",
       " 'presentation',\n",
       " 'Sepp',\n",
       " 'Hochreiter',\n",
       " 'Head',\n",
       " 'Institute',\n",
       " 'Bioinformatics',\n",
       " 'JKU',\n",
       " 'Linz',\n",
       " 'Sepp',\n",
       " 'Hochreiter',\n",
       " 'Institute',\n",
       " 'Bioinformatics',\n",
       " 'Johannes',\n",
       " 'Kepler',\n",
       " 'University',\n",
       " 'Linz',\n",
       " 'Austria',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'pioneer',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'term',\n",
       " 'memory',\n",
       " 'LSTM',\n",
       " 'diploma',\n",
       " 'thesis',\n",
       " 'LSTM',\n",
       " 'Google',\n",
       " '’',\n",
       " 's',\n",
       " 'Android',\n",
       " 'speech',\n",
       " 'recognizer',\n",
       " 'Google',\n",
       " '’',\n",
       " 'Voice',\n",
       " 'transcription',\n",
       " 'Google',\n",
       " '’',\n",
       " 's',\n",
       " 'Allo',\n",
       " 'Apple',\n",
       " '’',\n",
       " 'QuickType',\n",
       " 'Currently',\n",
       " 'Sepp',\n",
       " 'Hochreiter',\n",
       " 'foundation',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'gradient',\n",
       " 'flow',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'research',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'drug',\n",
       " 'design',\n",
       " 'text',\n",
       " 'language',\n",
       " 'analysis',\n",
       " 'vision',\n",
       " 'driving',\n",
       " 'Learning',\n",
       " 'Than',\n",
       " 'Classification',\n",
       " 'Many',\n",
       " 'Deep',\n",
       " 'learning',\n",
       " 'field',\n",
       " 'classification',\n",
       " 'example',\n",
       " 'hand',\n",
       " 'imagenet',\n",
       " 'drop',\n",
       " 'sea',\n",
       " 'learning',\n",
       " 'sea',\n",
       " 'extent',\n",
       " 'talk',\n",
       " 'sampling',\n",
       " 'learning',\n",
       " 'Zalando',\n",
       " 'cooperation',\n",
       " 'Prof.',\n",
       " 'Dr.',\n",
       " 'Sepp',\n",
       " 'Hochreiter',\n",
       " 'team',\n",
       " 'JKU',\n",
       " 'Linz',\n",
       " 'image',\n",
       " 'generation',\n",
       " 'Generative',\n",
       " 'Adversarial',\n",
       " 'Networks',\n",
       " 'Semi',\n",
       " 'Semantic',\n",
       " 'Segmentation',\n",
       " 'Warehouse',\n",
       " 'Optimization',\n",
       " 'Recommender',\n",
       " 'View',\n",
       " 'presentation',\n",
       " 'Calvin',\n",
       " 'Seward',\n",
       " 'Research',\n",
       " 'Scientist',\n",
       " 'Zalando',\n",
       " 'Calvin',\n",
       " 'Seward',\n",
       " 'Resarch',\n",
       " 'Scientist',\n",
       " 'Zalando',\n",
       " 'Research',\n",
       " 'Lab',\n",
       " 'PhD',\n",
       " 'student',\n",
       " 'Prof.',\n",
       " 'Dr.',\n",
       " 'Sepp',\n",
       " 'Hochreiter',\n",
       " 'JKU',\n",
       " 'Linz',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'classification',\n",
       " 'localization',\n",
       " 'segmentation',\n",
       " 'image',\n",
       " 'generation',\n",
       " 'line',\n",
       " 'attack',\n",
       " 'Tensorflow',\n",
       " 'framework',\n",
       " 'GPU',\n",
       " 'time',\n",
       " 'GPU-driven',\n",
       " 'HPC',\n",
       " 'computing',\n",
       " 'edge',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'Zalando',\n",
       " 'universe',\n",
       " 'management',\n",
       " 'recommendation',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'Opportunity',\n",
       " 'Gartner',\n",
       " 'year',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'peak',\n",
       " 'time',\n",
       " 'sea',\n",
       " 'opportunity',\n",
       " 'view',\n",
       " 'path',\n",
       " 'talk',\n",
       " 'perspective',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'use',\n",
       " 'industry',\n",
       " 'success',\n",
       " 'Ideation',\n",
       " 'process',\n",
       " 'data',\n",
       " 'Efficient',\n",
       " 'setup',\n",
       " 'Recruiting',\n",
       " 'retaining',\n",
       " 'Ulla',\n",
       " 'Kruhse-Lehtonen',\n",
       " 'CEO',\n",
       " 'DAIN',\n",
       " 'Studios',\n",
       " 'Ulla',\n",
       " 'CEO',\n",
       " 'DAIN',\n",
       " 'Studios',\n",
       " 'Data',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'product',\n",
       " 'startup',\n",
       " 'Finland',\n",
       " 'DACH',\n",
       " 'career',\n",
       " 'micro-economist',\n",
       " 'management',\n",
       " 'turn',\n",
       " 'century',\n",
       " 'variety',\n",
       " 'supply',\n",
       " 'chain',\n",
       " 'optimization',\n",
       " 'billing',\n",
       " 'CRM',\n",
       " 'client',\n",
       " 'side',\n",
       " 'Consumer',\n",
       " 'Analytics',\n",
       " 'Nokia',\n",
       " 'Consumer',\n",
       " 'Analytics',\n",
       " 'Department',\n",
       " 'support',\n",
       " 'marketing',\n",
       " 'supply',\n",
       " 'chain',\n",
       " 'product',\n",
       " 'Nokia',\n",
       " '’',\n",
       " 'Sanoma',\n",
       " 'Vice',\n",
       " 'President',\n",
       " 'Consumer',\n",
       " 'Analytics',\n",
       " 'Insights',\n",
       " 'Ulla',\n",
       " 'Analytics',\n",
       " 'Center',\n",
       " 'Excellence',\n",
       " 'unit',\n",
       " 'operating',\n",
       " 'Finland',\n",
       " 'Netherlands',\n",
       " 'Sanoma',\n",
       " '’',\n",
       " 'business',\n",
       " 'Ulla',\n",
       " 'Information',\n",
       " 'Leader',\n",
       " 'Year',\n",
       " 'Finland',\n",
       " 'PhD',\n",
       " 'Economics',\n",
       " 'Helsinki',\n",
       " 'School',\n",
       " 'Economics/',\n",
       " 'Aalto',\n",
       " 'University',\n",
       " 'Machine',\n",
       " 'Google',\n",
       " 'Cloud',\n",
       " 'Artificial',\n",
       " 'intelligence',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'Google',\n",
       " 'machine',\n",
       " 'part',\n",
       " 'Google',\n",
       " 'Cloud',\n",
       " 'scientist',\n",
       " 'software',\n",
       " 'session',\n",
       " 'machine',\n",
       " 'Google',\n",
       " 'Google',\n",
       " 'Cloud',\n",
       " 'TensorFlow',\n",
       " 'machine',\n",
       " 'platform',\n",
       " 'research',\n",
       " 'production',\n",
       " 'Google',\n",
       " 'Cloud',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'Engine',\n",
       " 'service',\n",
       " 'machine',\n",
       " 'type',\n",
       " 'size',\n",
       " 'APIs',\n",
       " 'application',\n",
       " 'programming',\n",
       " 'APIs',\n",
       " 'allow',\n",
       " 'software',\n",
       " 'ML',\n",
       " 'image',\n",
       " 'analysis',\n",
       " 'video',\n",
       " 'analysis',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " 'analysis',\n",
       " 'translation',\n",
       " 'Dave',\n",
       " 'Elliott',\n",
       " 'Global',\n",
       " 'Product',\n",
       " 'Lead',\n",
       " 'Google',\n",
       " 'Dave',\n",
       " 'Elliott',\n",
       " 'technology',\n",
       " 'evangelist',\n",
       " 'Architect',\n",
       " 'Advocate',\n",
       " 'platform',\n",
       " 'Google',\n",
       " 'role',\n",
       " 'voice',\n",
       " 'product',\n",
       " 'engineering',\n",
       " 'Prior',\n",
       " 'Google',\n",
       " 'Elliott',\n",
       " 'Cloud',\n",
       " 'Evangelist',\n",
       " 'Symantec',\n",
       " 'storage',\n",
       " 'Mr.',\n",
       " 'Elliott',\n",
       " 'advocate',\n",
       " 'cloud',\n",
       " 'while',\n",
       " 'Sun',\n",
       " 'career',\n",
       " 'Mr.',\n",
       " 'Elliott',\n",
       " 'MBA',\n",
       " 'University',\n",
       " 'California',\n",
       " 'Berkeley',\n",
       " 'BA',\n",
       " 'Quantitative',\n",
       " 'Economics',\n",
       " 'Decision',\n",
       " 'University',\n",
       " 'California',\n",
       " 'San',\n",
       " 'Diego',\n",
       " 'Neural',\n",
       " 'Networks',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'Artificial',\n",
       " 'machine',\n",
       " 'language',\n",
       " 'talk',\n",
       " 'network',\n",
       " 'language',\n",
       " 'recognition',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'word',\n",
       " 'classification',\n",
       " 'dataset',\n",
       " 'language',\n",
       " 'View',\n",
       " 'presentation',\n",
       " 'Tomáš',\n",
       " 'Mikolov',\n",
       " 'AI',\n",
       " 'Research',\n",
       " 'Scientist',\n",
       " 'Facebook',\n",
       " 'Tomáš',\n",
       " 'Mikolov',\n",
       " 'research',\n",
       " 'scientist',\n",
       " 'Facebook',\n",
       " 'AI',\n",
       " 'Research',\n",
       " 'group',\n",
       " 'member',\n",
       " 'Google',\n",
       " 'Brain',\n",
       " 'team',\n",
       " 'algorithms',\n",
       " 'word2vec',\n",
       " 'project',\n",
       " 'PhD',\n",
       " 'Brno',\n",
       " 'University',\n",
       " 'Technology',\n",
       " 'Czech',\n",
       " 'Republic',\n",
       " 'work',\n",
       " 'language',\n",
       " 'RNNLM',\n",
       " 'term',\n",
       " 'research',\n",
       " 'goal',\n",
       " 'function',\n",
       " 'g',\n",
       " 'r',\n",
       " 'm',\n",
       " '=r',\n",
       " 'r',\n",
       " ']',\n",
       " '=i',\n",
       " '[',\n",
       " 'r',\n",
       " ']',\n",
       " '||function',\n",
       " 'r',\n",
       " ']',\n",
       " '.q=i',\n",
       " '[',\n",
       " 'r',\n",
       " ']',\n",
       " '.q||',\n",
       " '[',\n",
       " ']',\n",
       " '.push',\n",
       " 'r',\n",
       " ']',\n",
       " '.l=1*new',\n",
       " 'Date',\n",
       " 'a=s.createElement',\n",
       " 'o',\n",
       " 'm=s.getElementsByTagName',\n",
       " ']',\n",
       " 'a.src=g',\n",
       " 'm.parentNode.insertBefore',\n",
       " 'm',\n",
       " 'document',\n",
       " \"'ga\",\n",
       " 'ga',\n",
       " \"'create\",\n",
       " \"'mostly.ai/summit\",\n",
       " 'ga',\n",
       " \"'pageview\",\n",
       " 'document.write',\n",
       " '<',\n",
       " 'script',\n",
       " 'src=',\n",
       " '>',\n",
       " '<',\n",
       " '\\\\/script',\n",
       " '>',\n",
       " 'typeof',\n",
       " '===',\n",
       " 'document.write',\n",
       " '<',\n",
       " 'script',\n",
       " 'src=',\n",
       " '>',\n",
       " '<',\n",
       " '\\\\/script',\n",
       " '>',\n",
       " 'Waves.displayEffect',\n",
       " 'document',\n",
       " '.ready',\n",
       " 'function',\n",
       " 'function',\n",
       " 'window',\n",
       " '.width',\n",
       " '[',\n",
       " ']',\n",
       " 'typeSpeed',\n",
       " 'backDelay',\n",
       " 'loop',\n",
       " 'name',\n",
       " 'Sepp',\n",
       " 'Hochreiter',\n",
       " 'company',\n",
       " 'JKU',\n",
       " 'Linz',\n",
       " 'Head',\n",
       " 'Institute',\n",
       " 'Bioinformatics',\n",
       " 'image',\n",
       " '/summit/img/people/SeppHochreiter.jpg',\n",
       " 'name',\n",
       " 'Calvin',\n",
       " 'Seward',\n",
       " 'company',\n",
       " 'Zalando',\n",
       " 'Research',\n",
       " 'Scientist',\n",
       " 'image',\n",
       " '/summit/img/people/CalvinSeward.jpg',\n",
       " 'name',\n",
       " 'Kruhse-Lehtonen',\n",
       " 'company',\n",
       " 'DAIN',\n",
       " 'Studios',\n",
       " 'CEO',\n",
       " 'image',\n",
       " '/summit/img/people/UllaKruhseLehtonen.jpg',\n",
       " 'name',\n",
       " 'Dave',\n",
       " 'Elliott',\n",
       " 'company',\n",
       " 'Google',\n",
       " 'Global',\n",
       " 'Product',\n",
       " 'Lead',\n",
       " 'image',\n",
       " '/summit/img/people/DaveElliot.jpg',\n",
       " 'name',\n",
       " 'Mikolov',\n",
       " 'company',\n",
       " 'Facebook',\n",
       " 'AI',\n",
       " 'Research',\n",
       " 'Scientist',\n",
       " 'image',\n",
       " '/summit/img/people/ThomasMikolov.jpg',\n",
       " ']',\n",
       " 'rockstarSpeakers.sort',\n",
       " 'function',\n",
       " 'Math.random',\n",
       " 'rockstarSpeakers.length',\n",
       " 'animationDelay',\n",
       " '=',\n",
       " 'count',\n",
       " '=',\n",
       " 'Math.min',\n",
       " 'rockstarSpeakers.length',\n",
       " 'i=0',\n",
       " 'count',\n",
       " 'i++',\n",
       " 'clearfix',\n",
       " '=',\n",
       " '<',\n",
       " 'div',\n",
       " 'class=',\n",
       " 'clearfix',\n",
       " 'visible-xs',\n",
       " '<',\n",
       " '/div',\n",
       " '>',\n",
       " '%',\n",
       " 'clearfix',\n",
       " '.after',\n",
       " '<',\n",
       " 'div',\n",
       " 'class=',\n",
       " 'colWidth',\n",
       " '+',\n",
       " 'rockstar-speakers-item',\n",
       " 'hiding',\n",
       " 'data-animation=',\n",
       " 'fadeInUp',\n",
       " 'data-delay=',\n",
       " 'animationDelay',\n",
       " '+',\n",
       " '<',\n",
       " 'div',\n",
       " 'class=',\n",
       " 'rockstar-speaker',\n",
       " '<',\n",
       " 'class=',\n",
       " 'rockstar-speaker-img',\n",
       " 'style=',\n",
       " 'background-image',\n",
       " 'url',\n",
       " '+',\n",
       " '+',\n",
       " '<',\n",
       " '/div',\n",
       " '>',\n",
       " '<',\n",
       " 'div',\n",
       " 'class=',\n",
       " 'name',\n",
       " '>',\n",
       " '+',\n",
       " '<',\n",
       " '/div',\n",
       " '>',\n",
       " '<',\n",
       " 'div',\n",
       " 'class=',\n",
       " 'sub',\n",
       " '>',\n",
       " '+',\n",
       " '<',\n",
       " '/div',\n",
       " '>',\n",
       " '<',\n",
       " '/div',\n",
       " '>',\n",
       " '<',\n",
       " '/div',\n",
       " '>',\n",
       " '+',\n",
       " 'clearfix',\n",
       " 'context',\n",
       " 'http',\n",
       " '//schema.org',\n",
       " 'type',\n",
       " 'Event',\n",
       " 'name',\n",
       " 'AI',\n",
       " 'Summit',\n",
       " 'Vienna',\n",
       " 'description',\n",
       " 'AI',\n",
       " 'Summit',\n",
       " 'Vienna',\n",
       " 'image',\n",
       " 'https',\n",
       " 'https',\n",
       " 'startDate',\n",
       " 'doorTime',\n",
       " 'endDate',\n",
       " 'location',\n",
       " 'type',\n",
       " 'Place',\n",
       " 'name',\n",
       " 'Learning',\n",
       " 'Center',\n",
       " 'WU',\n",
       " 'Campus',\n",
       " 'sameAs',\n",
       " 'https',\n",
       " '//goo.gl/maps/M7rdWybAQM62',\n",
       " 'address',\n",
       " 'type',\n",
       " 'PostalAddress',\n",
       " 'streetAddress',\n",
       " 'Wien',\n",
       " 'Austria',\n",
       " 'addressLocality',\n",
       " 'Vienna',\n",
       " 'addressRegion',\n",
       " 'postalCode',\n",
       " 'addressCountry',\n",
       " 'Austria',\n",
       " 'geo',\n",
       " 'type',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'organizer',\n",
       " 'type',\n",
       " 'Organization',\n",
       " 'name',\n",
       " 'Mostly',\n",
       " 'AI',\n",
       " 'Vienna',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'Meetup',\n",
       " 'alternateName',\n",
       " 'Mostly',\n",
       " 'AI',\n",
       " 'Vienna',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'Meetup',\n",
       " 'description',\n",
       " 'logo',\n",
       " 'https',\n",
       " 'email',\n",
       " 'summit',\n",
       " 'mostly.ai',\n",
       " 'sameAs',\n",
       " 'http',\n",
       " '//mostly.ai/',\n",
       " '//',\n",
       " 'subEvent',\n",
       " 'type',\n",
       " 'Event',\n",
       " 'name',\n",
       " 'description',\n",
       " 'image',\n",
       " 'https',\n",
       " 'https',\n",
       " 'startDate',\n",
       " 'doorTime',\n",
       " 'endDate',\n",
       " 'location',\n",
       " 'type',\n",
       " 'Place',\n",
       " 'name',\n",
       " 'sameAs',\n",
       " 'address',\n",
       " 'type',\n",
       " 'PostalAddress',\n",
       " 'streetAddress',\n",
       " 'addressLocality',\n",
       " 'addressRegion',\n",
       " 'postalCode',\n",
       " 'addressCountry',\n",
       " 'geo',\n",
       " 'type',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'type',\n",
       " 'Offer',\n",
       " 'name',\n",
       " 'Attendance',\n",
       " 'https',\n",
       " 'price',\n",
       " 'priceCurrency',\n",
       " 'EUR',\n",
       " 'validFrom',\n",
       " 'validThrough',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allnouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the Stanford Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\AAA_ProgrammingFiles\\\\AAA_Learning\\\\AAA_Moocs\\\\Coursera_NLP-Introduction\\\\Processing Raw Text'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To import we have to point to the original file\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "stan_tagger = StanfordPOSTagger('./models/stanford-tagger/models/english-bidirectional-distsim.tagger', './models/stanford-tagger/stanford-postagger.jar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "stanf_tagger = StanfordPOSTagger(\"./models/stanford-tagger/models/english-bidirectional-distsim.tagger\", \"./models/stanford-tagger/stanford-postagger.jar\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tag the Data in Sequences of 2500's\n",
    "def tag_tokens(tokens, tagger):\n",
    "    \"Was necessary because running it without batches caused a program exit\"\n",
    "    tagged_tokens = []\n",
    "    for i in range(0,len(tokens), 250):\n",
    "        tagged_tokens.append(tagger.tag(tokens[i:i+250]))\n",
    "    return [token for batches in tagged_tokens for token in batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_tokens = tag_tokens(tokens, stanf_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, tuple found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-3b45259306e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstanf_ner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\stanford.py\u001b[0m in \u001b[0;36mtag\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;31m# This function should return list of tuple rather than list of list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\stanford.py\u001b[0m in \u001b[0;36mtag_sents\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m# Write the actual sentences to the temporary input file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0m_input_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfdopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_input_fh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0m_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0m_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\stanford.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m# Write the actual sentences to the temporary input file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0m_input_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfdopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_input_fh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0m_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0m_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, tuple found"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
