{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Spell Correction for Text preprocessing\n",
    "\n",
    "This is an ongoing improvement on the core implemenation of the Spell <br>checking algorithm created By Peter Norvig\n",
    "for more information on [modeling basicss](http://norvig.com/spell-correct.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.metrics import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Basic_Processing.ipynb',\n",
       " 'data',\n",
       " 'HTML - Text Extraction.ipynb',\n",
       " 'Loading_from_Filesources.ipynb',\n",
       " 'Spell_correction.ipynb',\n",
       " 'Stemming_Lemmatizing_Words.ipynb',\n",
       " 'Untitled.ipynb',\n",
       " 'Working_with_sentences.ipynb']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementing a basic spell checker from Peter Norvig\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize the words\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "WORDS = Counter(words(open('./data/big.txt', 'r').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_spelling(text):\n",
    "    \"\"\"\n",
    "    Spell corrects a text for the English language. \n",
    "    \n",
    "    Given a string of Text and a trained FreqDict of a given language, the model\n",
    "    tries to Spell correct the sentences keeping original Formatting and Casing in place.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    def splits(word):\n",
    "        \"Return a list of all possible (first, rest) pairs that comprise word.\"\n",
    "        return [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "    \n",
    "    def correct(word):\n",
    "        \"Find the best spelling correction for this word.\"\n",
    "        # Prefer edit distance 0, then 1, then 2; otherwise default to word itself.\n",
    "        candidates = (known(edits0(word)) or \n",
    "                      known(edits1(word)) or \n",
    "                      known(edits2(word)) or \n",
    "                      [word])\n",
    "        return max(candidates, key=WORDS.get)\n",
    "    \n",
    "    def correct_text(text):\n",
    "        \"Correct all the words within a text, returning the corrected text.\"\n",
    "        return re.sub('[a-zA-Z]+', correct_match, text)\n",
    "    \n",
    "    def correct_match(match):\n",
    "        \"Spell-correct word in match, and preserve proper upper/lower/title case.\"\n",
    "        word = match.group()\n",
    "        return case_of(word)(correct(word.lower()))\n",
    "    \n",
    "    def case_of(text):\n",
    "        \"Return the case-function appropriate for text: upper, lower, title, or just str.\"\n",
    "        return (str.upper if text.isupper() else\n",
    "                str.lower if text.islower() else\n",
    "                str.title if text.istitle() else\n",
    "                str)\n",
    "    \n",
    "    def candidates(word):\n",
    "        \"Generate probable spelling corrections for word\"\n",
    "        return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "    \n",
    "    def known(words):\n",
    "        \"The subset of 'words' that appear in the dictionary of WORDS\"\n",
    "        return {w for w in words if w in WORDS}\n",
    "    \n",
    "    def edits0(word):\n",
    "        return {word}\n",
    "    \n",
    "    def edits1(word):\n",
    "        \"Return all strings that are one edit away from this word.\"\n",
    "        pairs      = splits(word)\n",
    "        deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "        transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "        replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "        inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(word):\n",
    "        \"All edits that are two edits away from word\"\n",
    "        return {e2 for e1 in edits1(word) for e2 in edits1(e1)}\n",
    "    \n",
    "    return correct_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spelling'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_spelling('Speling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 79809),\n",
       " ('of', 40024),\n",
       " ('and', 38312),\n",
       " ('to', 28765),\n",
       " ('in', 22023),\n",
       " ('a', 21124),\n",
       " ('that', 12512),\n",
       " ('he', 12401),\n",
       " ('was', 11410),\n",
       " ('it', 10681)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spelling Errors IN something. Whatever; unusual mistakes?'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"Speling Errurs IN somethink. Whutever; unusuel misteakes?\"\n",
    "check_spelling(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the joint propability of a given sentence\n",
    "\n",
    "We should be able to compute the probability of a word, P(w)P(w). We do that with the function pdist, which takes as input a Counter (hat is, a bag of words) and returns a function that acts as a probability distribution over all possible words. In a probability distribution the probability of each word is between 0 and 1, and the sum of the probabilities is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pdist(counter):\n",
    "    \"Calculates the prior propability of a given Word\"\n",
    "    N = sum(counter.values())\n",
    "    return lambda x: counter[x]/N\n",
    "\n",
    "def product(nums):\n",
    "    \"Multiply the numbers together, like sum but with multiply\"\n",
    "    result = 1\n",
    "    for x in nums:\n",
    "        result *= x\n",
    "    return result\n",
    "\n",
    "Pword = pdist(WORDS)\n",
    "\n",
    "def Pwords(words):\n",
    "    \"Propability of word\"\n",
    "    return product(Pword(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.870225938180123e-11, 8.233100124308226e-16, 0.0]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = ['this is a test', \n",
    "         'this is a unusual test',\n",
    "         'this is a neverbeforeseen test']\n",
    "\n",
    "[Pwords(words(text)) for text in tests]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sentence propability count to solve Word Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make one segmentation, into a first word and remaining characters. If we assume words are independent then we can maximize the probability of the first word adjoined to the best segmentation of the remaining characters.\n",
    "\n",
    "assert segment('choosespain') == ['choose', 'spain']\n",
    "\n",
    "segment('choosespain') ==\n",
    "   max(Pwords(['c'] + segment('hoosespain')),<br>\n",
    "       Pwords(['ch'] + segment('oosespain')),<br>\n",
    "       Pwords(['cho'] + segment('osespain')),<br>\n",
    "       Pwords(['choo'] + segment('sespain')),<br>\n",
    "       ...<br>\n",
    "       Pwords(['choosespain'] + segment('')))<br>\n",
    "       \n",
    "<br><br>\n",
    "To make this somewhat efficient, we need to avoid re-computing the segmentations of the remaining characters. This can be done explicitly by dynamic programming or implicitly with memoization. Also, we shouldn't consider all possible lengths for the first word; we can impose a maximum length. What should it be? A little more than the longest word seen so far.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    \"Memoize function f, whose args must all be hashable\"\n",
    "    cache = {}\n",
    "    def fmemo(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = f(*args)\n",
    "        return cache[args]\n",
    "    fmemo.cache = cache\n",
    "    return fmemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splits(text, start=0, L=20):\n",
    "    \"Returns a list of all (first, rest) pairs: start <= len(first) <= L\"\n",
    "    return [(text[:i], text[i:])  for i in range(start, min(len(text), L)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('r', 'eallylongtextwithacoupleofwords'),\n",
       " ('re', 'allylongtextwithacoupleofwords'),\n",
       " ('rea', 'llylongtextwithacoupleofwords'),\n",
       " ('real', 'lylongtextwithacoupleofwords'),\n",
       " ('reall', 'ylongtextwithacoupleofwords'),\n",
       " ('really', 'longtextwithacoupleofwords'),\n",
       " ('reallyl', 'ongtextwithacoupleofwords'),\n",
       " ('reallylo', 'ngtextwithacoupleofwords'),\n",
       " ('reallylon', 'gtextwithacoupleofwords'),\n",
       " ('reallylong', 'textwithacoupleofwords')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits('reallylongtextwithacoupleofwords', 1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memo\n",
    "def segment(text):\n",
    "    \"Return a list of words that is the most probable segmentation of text\"\n",
    "    if not text:\n",
    "        return []\n",
    "    else:\n",
    "        candidates = ([first] + segment(rest) for (first, rest) in splits(text,1))\n",
    "        return max(candidates, key=Pwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['really', 'long', 'text', 'with', 'a', 'couple', 'of', 'words']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment('reallylongtextwithacoupleofwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
